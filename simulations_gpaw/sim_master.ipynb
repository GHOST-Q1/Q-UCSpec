{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Step 1. Build a CaF₂ Cluster with ASE",
   "id": "c1ff50f66429b5b5"
  },
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "code",
   "source": [
    "from ase import Atoms\n",
    "from ase.build import make_supercell\n",
    "from ase.io import write\n",
    "from ase.build import bulk\n",
    "from ase.cluster import wulff_construction\n",
    "from ase.io import write, read\n",
    "\n",
    "# Build CaF2 fluorite unit cell\n",
    "caf2 = bulk('CaF2', 'fluorite', a=5.46)  # experimental lattice ~5.46 Å\n",
    "\n",
    "# Cut out a small cluster (~1 nm) with CaF2 stoichiometry\n",
    "# (Alternative: just take supercell and slice central atoms)\n",
    "cluster = caf2.repeat((2,2,2))  # 2x2x2 supercell\n",
    "cluster.center(vacuum=6.0)\n",
    "\n",
    "write(\"caf2_cluster.xyz\", cluster)\n",
    "atoms = read(\"caf2_cluster.xyz\")\n",
    "print(f\"Atoms: {len(atoms)}\")\n",
    "print(f\"Formula: {atoms.get_chemical_formula()}\")\n",
    "print(f\"Cell dimensions (Å): {atoms.cell.cellpar()}\")\n",
    "print(\"Cluster with\", len(cluster), \"atoms written to caf2_cluster.xyz\")"
   ],
   "id": "f87ef81d47ca9cfd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Step 2. Build a CaF₂:Er Cluster with ASE",
   "id": "93fd1b29d0c887ff"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from ase.build import bulk\n",
    "from ase.io import write\n",
    "import numpy as np\n",
    "\n",
    "# Step 1: Build CaF2 fluorite cell\n",
    "caf2 = bulk('CaF2', 'fluorite', a=5.46)\n",
    "\n",
    "# Step 2: Make a small cluster (supercell with vacuum)\n",
    "cluster = caf2.repeat((2,2,2))\n",
    "cluster.center(vacuum=6.0)\n",
    "\n",
    "# Step 3: Substitute one Ca -> Er to get Ca3:Er ratio in cluster\n",
    "symbols = cluster.get_chemical_symbols()\n",
    "ca_indices = [i for i, s in enumerate(symbols) if s == \"Ca\"]\n",
    "\n",
    "if len(ca_indices) < 4:\n",
    "    raise RuntimeError(\"Not enough Ca atoms to make Ca3:Er substitution!\")\n",
    "\n",
    "# Replace the 4th Ca with Er\n",
    "symbols[ca_indices[3]] = \"Er\"\n",
    "cluster.set_chemical_symbols(symbols)\n",
    "\n",
    "# Step 4: Save\n",
    "write(\"caf2_er_cluster.xyz\", cluster)\n",
    "atoms = read(\"caf2_er_cluster.xyz\")\n",
    "print(f\"Atoms: {len(atoms)}\")\n",
    "print(f\"Formula: {atoms.get_chemical_formula()}\")\n",
    "print(f\"Cell dimensions (Å): {atoms.cell.cellpar()}\")\n",
    "print(\"Cluster with\", len(cluster), \"atoms written to caf2_er_cluster.xyz\")"
   ],
   "id": "cd7223a1dceafc6f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "3. Simulate",
   "id": "d283e8b28f42f055"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "import os, sys, time, inspect, psutil\n",
    "# Determine project root (Q-UCSpec) and unified output directory\n",
    "_project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "OUT_DIR = os.path.join(_project_root, \"spectra-results\")\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "# Centralized data directory for all CSV outputs\n",
    "DATA_DIR = os.path.join(_project_root, \"data\")\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "import numpy as np\n",
    "from ase.io import read, write\n",
    "from ase.optimize import LBFGS\n",
    "from gpaw import GPAW, FermiDirac\n",
    "from gpaw.tddft import TDDFT\n",
    "from gpaw.mixer import Mixer, MixerSum, MixerDif\n",
    "from gpaw.poisson import PoissonSolver\n",
    "from gpaw import GPAW\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from gpaw.lrtddft import LrTDDFT\n",
    "\n",
    "\n",
    "# --- DeltaKick ---\n",
    "class DeltaKick:\n",
    "    def __init__(self, strength=0.001, direction=(1, 0, 0)):\n",
    "        self._strength = strength\n",
    "        self.direction = np.array(direction, dtype=float)\n",
    "        self.applied = False\n",
    "\n",
    "    def strength(self, time):\n",
    "        if not self.applied and abs(time) < 1e-8:\n",
    "            self.applied = True\n",
    "            return self._strength * self.direction\n",
    "        return np.zeros(3)\n",
    "\n",
    "\n",
    "# --- Step 1: Safer LCAO Relax ---\n",
    "def relax_lcao(xyz_file):\n",
    "    \"\"\"\n",
    "    Relax cluster geometry in LCAO mode with safer SCF settings.\n",
    "    Uses gentle mixing and looser criteria to improve convergence.\n",
    "    \"\"\"\n",
    "    name = os.path.splitext(xyz_file)[0]\n",
    "    gpw_lcao = f\"{name}_lcao.gpw\"\n",
    "\n",
    "    # Load system\n",
    "    atoms = read(xyz_file)\n",
    "    atoms.center(vacuum=10.0)\n",
    "\n",
    "    # Calculator with cluster-friendly SCF settings\n",
    "    calc = GPAW(mode=\"lcao\",\n",
    "                basis=\"dzp\",\n",
    "                xc=\"PBE\",\n",
    "                occupations=FermiDirac(0.1),   # slightly larger smearing\n",
    "                kpts=(1, 1, 1),\n",
    "                mixer={'backend': 'pulay',\n",
    "                       'beta': 0.05,    # gentler mixing\n",
    "                       'nmaxold': 5,    # fewer densities kept\n",
    "                       'weight': 50.0}, # softer damping\n",
    "                convergence={'energy': 1e-2, 'density': 1e-2},\n",
    "                txt=f\"{name}_lcao.log\")\n",
    "    atoms.calc = calc\n",
    "\n",
    "    # Initial SCF to stabilize density before relaxation\n",
    "    print(\"Running initial SCF to stabilize density...\")\n",
    "    atoms.get_potential_energy()\n",
    "\n",
    "    # Geometry optimization (looser fmax first)\n",
    "    dyn = LBFGS(atoms, logfile=f\"{name}_lcao_opt.log\")\n",
    "    dyn.run(fmax=0.15, steps=200)   # relaxed force tolerance\n",
    "\n",
    "    # Save results\n",
    "    calc.write(gpw_lcao, mode=\"all\")\n",
    "    write(f\"{name}_lcao_relaxed.xyz\", atoms)\n",
    "    print(f\"✔ {name}: saved {gpw_lcao}\")\n",
    "    return gpw_lcao\n",
    "\n",
    "\n",
    "# --- Step 2: FD Restart---\n",
    "def groundstate_fd(gpw_lcao, virt_buffer=20, h=0.30):\n",
    "    name = gpw_lcao.replace(\"_lcao.gpw\", \"_fd\")\n",
    "    gpw_fd = f\"{name}.gpw\"\n",
    "    if os.path.exists(gpw_fd):\n",
    "        print(f\"Using cached {gpw_fd}\")\n",
    "        return gpw_fd\n",
    "\n",
    "    lcao_calc = GPAW(gpw_lcao)\n",
    "    n_occ = int(np.ceil(lcao_calc.get_number_of_electrons() / 2.0))\n",
    "    n_bands = n_occ + virt_buffer\n",
    "\n",
    "    calc = GPAW(gpw_lcao,\n",
    "                mode=\"fd\",\n",
    "                h=h,\n",
    "                xc=\"PBE\",\n",
    "                occupations=FermiDirac(0.03),\n",
    "                nbands=n_bands,\n",
    "                poissonsolver=PoissonSolver('fd', eps=1e-12),\n",
    "                mixer={\"beta\": 0.05, \"nmaxold\": 10, \"weight\": 100},\n",
    "                convergence={\"energy\": 3e-4, \"density\": 2e-4, \"eigenstates\": 4},\n",
    "                symmetry={\"point_group\": False},\n",
    "                txt=f\"{name}.log\")\n",
    "    calc.get_potential_energy()\n",
    "    calc.write(gpw_fd, mode=\"all\")\n",
    "    return gpw_fd\n",
    "\n",
    "\n",
    "#  --- Step 3: TDDFT Runner (Modern GPAW ≥ 25.x) -----\n",
    "def run_lrtddft(gpw_fd, prefix=\"system\", emax=10.0, sigma=0.1):\n",
    "    \"\"\"Linear-Response TDDFT with auto memory and auto state detection.\"\"\"\n",
    "    print(f\"\\n=== Running LrTDDFT on {gpw_fd} ===\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    calc = GPAW(gpw_fd)\n",
    "    free_mem_gb = psutil.virtual_memory().available / 1e9\n",
    "    total_states = len(calc.get_eigenvalues())\n",
    "    print(f\"Available RAM ≈ {free_mem_gb:.2f} GB | KS states = {total_states}\")\n",
    "\n",
    "    # --- Run modern LrTDDFT ---\n",
    "    try:\n",
    "        lr = LrTDDFT(calc)\n",
    "        lr.diagonalize()\n",
    "        print(\"TDDFT: modern auto-state solver active.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Fallback legacy solver due to: {e}\")\n",
    "        lr = LrTDDFT(calc)\n",
    "        lr.diagonalize()\n",
    "\n",
    "    # --- Extract excitations ---\n",
    "    energies, osc = [], []\n",
    "    for exc in lr:\n",
    "        e = exc.get_energy() * 27.2114  # eV\n",
    "        f = np.linalg.norm(exc.get_oscillator_strength())\n",
    "        if e <= emax:\n",
    "            energies.append(e)\n",
    "            osc.append(f)\n",
    "    print(f\"Extracted {len(energies)} excitations below {emax:.1f} eV.\")\n",
    "\n",
    "    # --- Save raw data ---\n",
    "    np.savetxt(os.path.join(DATA_DIR, f\"{prefix}_sticks.csv\"),\n",
    "               np.column_stack([energies, osc]),\n",
    "               delimiter=\",\", header=\"Energy(eV),OscStrength\", comments=\"\")\n",
    "\n",
    "    # --- Broaden and plot spectrum ---\n",
    "    x = np.linspace(0, emax + 0.5, 1000)\n",
    "    y = np.zeros_like(x)\n",
    "    for e, f in zip(energies, osc):\n",
    "        y[np.argmin(np.abs(x - e))] += f\n",
    "    y_smooth = gaussian_filter1d(y, sigma * 100)\n",
    "\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.plot(x, y_smooth, label=f\"{prefix}\")\n",
    "    plt.scatter(energies, osc, c=\"red\", s=15, label=\"Excitations\")\n",
    "    plt.xlabel(\"Energy (eV)\")\n",
    "    plt.ylabel(\"Oscillator strength (a.u.)\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    try:\n",
    "        OUT_DIR\n",
    "    except NameError:\n",
    "        _project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "        OUT_DIR = os.path.join(_project_root, \"spectra-results\")\n",
    "        os.makedirs(OUT_DIR, exist_ok=True)\n",
    "    plt.savefig(os.path.join(OUT_DIR, f\"{prefix}_spectrum.png\"), dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    runtime = (time.time() - start_time)/60\n",
    "    print(f\"TDDFT runtime: {runtime:.2f} min | Saved: {os.path.join(OUT_DIR, f'{prefix}_spectrum.png')}\\n\")\n",
    "\n",
    "    return os.path.join(DATA_DIR, f\"{prefix}_sticks.csv\"), os.path.join(OUT_DIR, f\"{prefix}_spectrum.png\")\n",
    "\n",
    "# -----------------------------------------------------\n",
    "#  Main Simulation Pipeline\n",
    "# -----------------------------------------------------\n",
    "def run_pipeline(xyz_file):\n",
    "    prefix = xyz_file.replace(\".xyz\", \"\")\n",
    "    gpw_lcao = f\"{prefix}_lcao.gpw\"\n",
    "    gpw_fd   = f\"{prefix}_fd.gpw\"\n",
    "    spec_csv = os.path.join(DATA_DIR, f\"{prefix}_sticks.csv\")\n",
    "    spec_png = os.path.join(OUT_DIR, f\"{prefix}_spectrum.png\")\n",
    "\n",
    "    print(f\"\\n=== Starting pipeline for {prefix} ===\")\n",
    "\n",
    "    # --- Step 1: Relax geometry (LCAO) ---\n",
    "    if os.path.exists(gpw_lcao):\n",
    "        print(f\"✔ Cached LCAO found: {gpw_lcao}\")\n",
    "    else:\n",
    "        print(f\"Running LCAO relaxation for {prefix} …\")\n",
    "        gpw_lcao = relax_lcao(xyz_file)\n",
    "\n",
    "    # --- Step 2: Ground-state FD calculation ---\n",
    "    if os.path.exists(gpw_fd):\n",
    "        print(f\"✔ Cached FD found: {gpw_fd}\")\n",
    "    else:\n",
    "        print(f\"Running FD ground state for {prefix} …\")\n",
    "        gpw_fd = groundstate_fd(gpw_lcao)\n",
    "\n",
    "    # --- Step 3: TDDFT spectrum ---\n",
    "    if os.path.exists(spec_csv):\n",
    "        print(f\"✔ TDDFT already complete — skipping.\")\n",
    "        return spec_csv, spec_png\n",
    "    else:\n",
    "        sticks, spectrum = run_lrtddft(gpw_fd, prefix=prefix)\n",
    "        print(f\"TDDFT complete: {sticks}, {spectrum}\")\n",
    "        return sticks, spectrum\n",
    "\n",
    "# Run on bulk cluster\n",
    "#spectrum_files = run_pipeline(\"caf2_cluster.xyz\")\n",
    "# Run on Er-doped cluster\n",
    "spectrum_files = run_pipeline(\"caf2_er_cluster.xyz\")"
   ],
   "id": "a7d96074ba63dcb3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Enhanced statistical description for caf2_cluster_sticks.csv\n",
    "Generates terminal summary + Markdown report with key transition stats.\n",
    "\"\"\"\n",
    "\n",
    "import os, sys, csv, numpy as np, pandas as pd\n",
    "try:\n",
    "    from scipy.stats import skew, kurtosis  # type: ignore\n",
    "except Exception:\n",
    "    def skew(a):\n",
    "        a = np.asarray(a, dtype=float)\n",
    "        m = np.mean(a)\n",
    "        s = np.std(a)\n",
    "        if s == 0:\n",
    "            return 0.0\n",
    "        m3 = np.mean(((a - m) / s) ** 3)\n",
    "        return float(m3)\n",
    "    def kurtosis(a):\n",
    "        a = np.asarray(a, dtype=float)\n",
    "        m = np.mean(a)\n",
    "        s = np.std(a)\n",
    "        if s == 0:\n",
    "            return 0.0\n",
    "        m4 = np.mean(((a - m) / s) ** 4)\n",
    "        return float(m4 - 3.0)\n",
    "\n",
    "# Ensure DATA_DIR is defined for direct cell execution\n",
    "try:\n",
    "    DATA_DIR\n",
    "except NameError:\n",
    "    _project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "    DATA_DIR = os.path.join(_project_root, \"data\")\n",
    "    os.makedirs(DATA_DIR, exist_ok=True)\n",
    "\n",
    "FILENAME = os.path.join(DATA_DIR, \"caf2_cluster_sticks.csv\")\n",
    "OUTPUT_MD = \"caf2_cluster_sticks_summary.md\"\n",
    "\n",
    "# --- Safe load with legacy fallback ---\n",
    "if not os.path.exists(FILENAME):\n",
    "    # Try to locate a legacy CSV and copy it into DATA_DIR\n",
    "    legacy = None\n",
    "    legacy_candidates = [\n",
    "        os.path.join(os.getcwd(), \"caf2_cluster_sticks.csv\"),\n",
    "        os.path.join(_project_root, \"simulations_gpaw\", \"caf2_cluster_sticks.csv\"),\n",
    "    ]\n",
    "    for p in legacy_candidates:\n",
    "        if os.path.exists(p):\n",
    "            legacy = p\n",
    "            break\n",
    "    if legacy:\n",
    "        print(f\"[WARN] Missing data file; using legacy CSV at {legacy} and copying to {FILENAME} …\")\n",
    "        try:\n",
    "            import shutil\n",
    "            os.makedirs(os.path.dirname(FILENAME), exist_ok=True)\n",
    "            shutil.copyfile(legacy, FILENAME)\n",
    "            print(f\"[INFO] Copied legacy CSV into data directory: {FILENAME}\")\n",
    "        except Exception as ce:\n",
    "            print(f\"[WARN] Could not copy legacy CSV into data dir: {ce}\")\n",
    "\n",
    "if not os.path.exists(FILENAME):\n",
    "    sys.exit(f\"[ERROR] File not found: {FILENAME}\")\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(FILENAME)\n",
    "except Exception as e:\n",
    "    sys.exit(f\"[ERROR] Failed to load CSV: {e}\")\n",
    "\n",
    "# --- Flexible column detection ---\n",
    "colE = [c for c in df.columns if \"Energy\" in c][0]\n",
    "colF = [c for c in df.columns if \"Osc\" in c or \"f\" in c][0]\n",
    "\n",
    "E = df[colE].astype(float).to_numpy()\n",
    "F = df[colF].astype(float).to_numpy()\n",
    "\n",
    "if E.size == 0 or F.size == 0:\n",
    "    sys.exit(\"[ERROR] Empty dataset or unrecognized columns.\")\n",
    "\n",
    "# --- Derived quantities ---\n",
    "wl = 1240.0 / np.maximum(E, 1e-9)\n",
    "Σf = F.sum()\n",
    "E_mean, E_median = E.mean(), np.median(E)\n",
    "F_mean, F_median = F.mean(), np.median(F)\n",
    "centroid_E = (E * F).sum() / Σf if Σf > 0 else np.nan\n",
    "centroid_λ = 1240.0 / max(centroid_E, 1e-6)\n",
    "\n",
    "# --- Basic statistics ---\n",
    "stats = {\n",
    "    \"Transitions\": len(E),\n",
    "    \"Energy (eV) Range\": f\"{E.min():.3f} – {E.max():.3f}\",\n",
    "    \"Energy Mean / Median\": f\"{E_mean:.3f} / {E_median:.3f}\",\n",
    "    \"Osc. Strength Min / Mean / Median / Max\":\n",
    "        f\"{F.min():.3e} / {F_mean:.3e} / {F_median:.3e} / {F.max():.3e}\",\n",
    "    \"Σf (Total Osc. Strength)\": f\"{Σf:.6f}\",\n",
    "    \"Centroid Energy (eV)\": f\"{centroid_E:.3f}\",\n",
    "    \"Centroid Wavelength (nm)\": f\"{centroid_λ:.0f}\",\n",
    "    \"Energy Skewness\": f\"{skew(E):.3f}\",\n",
    "    \"Energy Kurtosis\": f\"{kurtosis(E):.3f}\",\n",
    "}\n",
    "\n",
    "# --- Display in terminal ---\n",
    "print(\"\\n=== caf2_cluster_sticks.csv Statistical Summary ===\")\n",
    "for k, v in stats.items():\n",
    "    print(f\"{k:35s}: {v}\")\n",
    "\n",
    "# --- Top 10 strongest transitions ---\n",
    "idx = np.argsort(F)[-10:][::-1]\n",
    "top_transitions = [(E[i], wl[i], F[i]) for i in idx]\n",
    "\n",
    "print(\"\\nTop 10 Transitions (strongest → weakest):\")\n",
    "for n, (e, lam, f) in enumerate(top_transitions, 1):\n",
    "    print(f\"{n:2d}. E = {e:6.3f} eV   λ ≈ {lam:6.0f} nm   f = {f:.3e}\")\n",
    "\n",
    "# --- Markdown report ---\n",
    "with open(OUTPUT_MD, \"w\") as f:\n",
    "    f.write(\"# CaF₂ Cluster TDDFT Stick Data Summary\\n\\n\")\n",
    "    f.write(\"| Metric | Value |\\n|:--|:--|\\n\")\n",
    "    for k, v in stats.items():\n",
    "        f.write(f\"| {k} | {v} |\\n\")\n",
    "    f.write(\"\\n## Top 10 Transitions\\n\\n\")\n",
    "    f.write(\"| # | Energy (eV) | Wavelength (nm) | Osc. Strength (f) |\\n|:-:|:-:|:-:|:-:|\\n\")\n",
    "    for n, (e, lam, fval) in enumerate(top_transitions, 1):\n",
    "        f.write(f\"| {n} | {e:.3f} | {lam:.0f} | {fval:.3e} |\\n\")"
   ],
   "id": "9b9ea87cb6c35794",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Prefer pandas if available; fall back to csv\n",
    "try:\n",
    "    import pandas as pd\n",
    "    df = pd.read_csv(os.path.join(DATA_DIR, \"caf2_cluster_sticks.csv\"))\n",
    "    cols = {c.lower().strip(): c for c in df.columns}\n",
    "    energy_col = cols.get('energy(ev)') or cols.get('energy') or list(df.columns)[0]\n",
    "    osc_col = cols.get('oscstrength') or cols.get('oscillator_strength') or list(df.columns)[1]\n",
    "    energies = df[energy_col].astype(float).to_numpy()\n",
    "    strengths = df[osc_col].astype(float).to_numpy()\n",
    "except Exception:\n",
    "    import csv\n",
    "    energies = []\n",
    "    strengths = []\n",
    "    with open(os.path.join(DATA_DIR, \"caf2_cluster_sticks.csv\"), \"r\", newline=\"\") as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        field_map = {k.lower().strip(): k for k in (reader.fieldnames or [])}\n",
    "        energy_key = field_map.get('energy(ev)') or field_map.get('energy')\n",
    "        osc_key = field_map.get('oscstrength') or field_map.get('oscillator_strength')\n",
    "        if energy_key is None or osc_key is None:\n",
    "            f.seek(0)\n",
    "            reader2 = csv.reader(f)\n",
    "            header = next(reader2, None)\n",
    "            for row in reader2:\n",
    "                if not row:\n",
    "                    continue\n",
    "                energies.append(float(row[0]))\n",
    "                strengths.append(float(row[1]))\n",
    "        else:\n",
    "            for row in reader:\n",
    "                energies.append(float(row[energy_key]))\n",
    "                strengths.append(float(row[osc_key]))\n",
    "    energies = np.array(energies, dtype=float)\n",
    "    strengths = np.array(strengths, dtype=float)\n",
    "\n",
    "# Plot sticks\n",
    "fig, ax = plt.subplots(figsize=(8, 4.5))\n",
    "ax.vlines(energies, 0, strengths, colors='#1f77b4', linewidth=1.0, alpha=0.9)\n",
    "ax.set_xlabel(\"Energy (eV)\")\n",
    "ax.set_ylabel(\"Oscillator Strength\")\n",
    "ax.set_title(\"CaF2 cluster stick spectrum\")\n",
    "\n",
    "# Nice bounds and grid\n",
    "ax.margins(x=0.02)\n",
    "ymax = strengths.max() if strengths.size else 1.0\n",
    "ax.set_ylim(0, ymax * 1.05)\n",
    "ax.grid(True, which='both', linestyle='--', linewidth=0.4, alpha=0.4)\n",
    "\n",
    "plt.tight_layout()\n",
    "try:\n",
    "    OUT_DIR\n",
    "except NameError:\n",
    "    _project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "    OUT_DIR = os.path.join(_project_root, \"spectra-results\")\n",
    "    os.makedirs(OUT_DIR, exist_ok=True)\n",
    "out_path = os.path.join(OUT_DIR, \"caf2_cluster_sticks.png\")\n",
    "plt.savefig(out_path, dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ],
   "id": "31c9a3271a4212ae",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- Load the data ---\n",
    "df = pd.read_csv(os.path.join(DATA_DIR, \"caf2_cluster_sticks.csv\"))\n",
    "\n",
    "# --- Identify columns automatically ---\n",
    "colE = [c for c in df.columns if \"Energy\" in c][0]\n",
    "colF = [c for c in df.columns if \"Osc\" in c or \"f\" in c][0]\n",
    "\n",
    "E = df[colE].astype(float).to_numpy()\n",
    "F = df[colF].astype(float).to_numpy()\n",
    "\n",
    "# --- Find the index of maximum oscillator strength ---\n",
    "idx_max = np.argmax(F)\n",
    "E_max = E[idx_max]\n",
    "F_max = F[idx_max]\n",
    "λ_max = 1240.0 / np.maximum(E_max, 1e-9)\n",
    "\n",
    "# --- Print results ---\n",
    "print(\"=== HIGHEST OSCILLATOR STRENGTH TRANSITION ===\")\n",
    "print(f\"Index: {idx_max}\")\n",
    "print(f\"Energy (eV): {E_max:.3f}\")\n",
    "print(f\"Wavelength (nm): {λ_max:.1f}\")\n",
    "print(f\"Oscillator Strength (f): {F_max:.6f}\")\n",
    "\n",
    "# --- Optional: save a filtered one-row CSV ---\n",
    "pd.DataFrame({\n",
    "    \"Energy (eV)\": [E_max],\n",
    "    \"Wavelength (nm)\": [λ_max],\n",
    "    \"Oscillator Strength (f)\": [F_max]\n",
    "}).to_csv(os.path.join(DATA_DIR, \"caf2_cluster_strongest_transition.csv\"), index=False)"
   ],
   "id": "acc4dc3e7ed3d97f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "csv_path = os.path.join(DATA_DIR, \"caf2_cluster_optical_properties_scaled.csv\")\n",
    "\n",
    "# Ensure optical properties CSV exists in DATA_DIR; otherwise, copy from legacy locations\n",
    "try:\n",
    "    _project_root\n",
    "except NameError:\n",
    "    _project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "\n",
    "if not os.path.exists(csv_path):\n",
    "    try:\n",
    "        import shutil\n",
    "    except Exception:\n",
    "        shutil = None\n",
    "    legacy_candidates = [\n",
    "        os.path.join(os.getcwd(), \"caf2_cluster_optical_properties_scaled.csv\"),\n",
    "        os.path.join(_project_root, \"simulations_gpaw\", \"caf2_cluster_optical_properties_scaled.csv\"),\n",
    "        os.path.join(_project_root, \"simulations_gpaw\", \"CaF\u0002 Cluster_optical_properties_scaled.csv\"),\n",
    "    ]\n",
    "    found_legacy = None\n",
    "    for p in legacy_candidates:\n",
    "        if os.path.exists(p):\n",
    "            found_legacy = p\n",
    "            break\n",
    "    if found_legacy and shutil is not None:\n",
    "        try:\n",
    "            os.makedirs(DATA_DIR, exist_ok=True)\n",
    "            shutil.copyfile(found_legacy, csv_path)\n",
    "            print(f\"[INFO] Copied legacy optical CSV from {found_legacy} to {csv_path}\")\n",
    "        except Exception as ce:\n",
    "            print(f\"[WARN] Could not copy legacy optical CSV: {ce}\")\n",
    "    if not os.path.exists(csv_path):\n",
    "        raise FileNotFoundError(f\"Optical properties CSV not found: {csv_path}\")\n",
    "\n",
    "# Prefer pandas if available; fall back to csv\n",
    "try:\n",
    "    import pandas as pd\n",
    "    df = pd.read_csv(csv_path)\n",
    "    cols = {c.lower().strip(): c for c in df.columns}\n",
    "    e_col = cols.get('energy(ev)') or cols.get('energy') or list(df.columns)[0]\n",
    "\n",
    "    # Try to find absorption alpha column (scaled)\n",
    "    alpha_candidates = ['alpha(cm^-1)', 'alpha (cm^-1)', 'alpha', 'absorption']\n",
    "    alpha_col = None\n",
    "    for key in alpha_candidates:\n",
    "        for c in df.columns:\n",
    "            if c.lower().strip() == key.lower():\n",
    "                alpha_col = c\n",
    "                break\n",
    "        if alpha_col:\n",
    "            break\n",
    "\n",
    "    # Optional: refractive index column\n",
    "    n_candidates = ['n', 'refractive_index', 'refractive index']\n",
    "    n_col = None\n",
    "    for key in n_candidates:\n",
    "        for c in df.columns:\n",
    "            if c.lower().strip() == key.lower():\n",
    "                n_col = c\n",
    "                break\n",
    "        if n_col:\n",
    "            break\n",
    "\n",
    "    E = df[e_col].astype(float).to_numpy()\n",
    "    alpha = df[alpha_col].astype(float).to_numpy() if alpha_col else None\n",
    "    nvals = df[n_col].astype(float).to_numpy() if n_col else None\n",
    "except Exception:\n",
    "    import csv\n",
    "    E, alpha, nvals = [], [], []\n",
    "    with open(csv_path, \"r\", newline=\"\") as f:\n",
    "        reader = csv.reader(f)\n",
    "        header = next(reader, [])\n",
    "        header_l = [h.lower().strip() for h in header]\n",
    "        def idx_of(keys):\n",
    "            for key in keys:\n",
    "                if key.lower() in header_l:\n",
    "                    return header_l.index(key.lower())\n",
    "            return None\n",
    "        iE = idx_of(['energy(eV)', 'energy', 'e'])\n",
    "        iA = idx_of(['alpha(cm^-1)', 'alpha (cm^-1)', 'alpha', 'absorption'])\n",
    "        iN = idx_of(['n', 'refractive_index', 'refractive index'])\n",
    "        for row in reader:\n",
    "            if not row:\n",
    "                continue\n",
    "            if iE is not None:\n",
    "                E.append(float(row[iE]))\n",
    "            if iA is not None:\n",
    "                alpha.append(float(row[iA]))\n",
    "            if iN is not None:\n",
    "                nvals.append(float(row[iN]))\n",
    "    E = np.array(E, dtype=float)\n",
    "    alpha = np.array(alpha, dtype=float) if len(alpha) else None\n",
    "    nvals = np.array(nvals, dtype=float) if len(nvals) else None\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(8, 4.5))\n",
    "\n",
    "if alpha is not None and np.size(alpha) == np.size(E):\n",
    "    ax.plot(E, alpha, color='tab:blue', lw=1.2, label='α (cm⁻¹)')\n",
    "    # α spans orders of magnitude; use log scale for readability\n",
    "    try:\n",
    "        ax.set_yscale('log')\n",
    "    except Exception:\n",
    "        pass\n",
    "    ax.set_ylabel('Absorption coefficient α (cm⁻¹)', color='tab:blue')\n",
    "else:\n",
    "    ax.plot(E, np.zeros_like(E), alpha=0)\n",
    "    ax.set_ylabel('Value')\n",
    "\n",
    "ax.set_xlabel('Energy (eV)')\n",
    "ax.set_title('CaF2 cluster optical properties (scaled)')\n",
    "ax.grid(True, which='both', linestyle='--', linewidth=0.4, alpha=0.4)\n",
    "\n",
    "# Optional secondary axis for refractive index n(E)\n",
    "if nvals is not None and np.size(nvals) == np.size(E):\n",
    "    ax2 = ax.twinx()\n",
    "    ax2.plot(E, nvals, color='tab:orange', lw=1.0, alpha=0.85, label='n')\n",
    "    ax2.set_ylabel('Refractive index n', color='tab:orange')\n",
    "    ax2.tick_params(axis='y', labelcolor='tab:orange')\n",
    "\n",
    "plt.tight_layout()\n",
    "try:\n",
    "    OUT_DIR\n",
    "except NameError:\n",
    "    _project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "    OUT_DIR = os.path.join(_project_root, \"spectra-results\")\n",
    "    os.makedirs(OUT_DIR, exist_ok=True)\n",
    "out_path = os.path.join(OUT_DIR, \"caf2_cluster_optical_properties_scaled.png\")\n",
    "plt.savefig(out_path, dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ],
   "id": "c1d6dba4a30aa295",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "import warnings\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mticker\n",
    "\n",
    "# Optional dependencies with graceful fallbacks\n",
    "try:\n",
    "    from scipy.integrate import simpson as _simpson\n",
    "except Exception:\n",
    "    _simpson = None\n",
    "\n",
    "try:\n",
    "    from scipy.ndimage import gaussian_filter1d as _gaussian_filter1d\n",
    "except Exception:\n",
    "    _gaussian_filter1d = None\n",
    "\n",
    "try:\n",
    "    from mpl_toolkits.axes_grid1.inset_locator import inset_axes as _inset_axes\n",
    "except Exception:\n",
    "    _inset_axes = None\n",
    "\n",
    "\n",
    "def _read_sticks_csv(path):\n",
    "    \"\"\"Read a TDDFT sticks CSV robustly. Returns (E, f) as float numpy arrays.\n",
    "    Accepts headers like 'Energy(eV), OscStrength' (case-insensitive) and falls\n",
    "    back to first two columns if headers unknown.\n",
    "    \"\"\"\n",
    "    # Prefer pandas if available\n",
    "    try:\n",
    "        import pandas as pd\n",
    "        df = pd.read_csv(path)\n",
    "        cols = {c.lower().strip(): c for c in df.columns}\n",
    "        e_col = cols.get('energy(eV)'.lower()) or cols.get('energy') or list(df.columns)[0]\n",
    "        f_col = cols.get('oscstrength') or cols.get('oscillator_strength') or list(df.columns)[1]\n",
    "        E = df[e_col].astype(float).to_numpy()\n",
    "        f = df[f_col].astype(float).to_numpy()\n",
    "        return E, f\n",
    "    except Exception:\n",
    "        import csv\n",
    "        E_list, f_list = [], []\n",
    "        with open(path, 'r', newline='') as fh:\n",
    "            # Try DictReader first\n",
    "            reader = csv.DictReader(fh)\n",
    "            field_map = {k.lower().strip(): k for k in (reader.fieldnames or [])}\n",
    "            ek = field_map.get('energy(eV)'.lower()) or field_map.get('energy')\n",
    "            fk = field_map.get('oscstrength') or field_map.get('oscillator_strength')\n",
    "            if ek is None or fk is None:\n",
    "                fh.seek(0)\n",
    "                rdr = csv.reader(fh)\n",
    "                _ = next(rdr, None)  # header maybe\n",
    "                for row in rdr:\n",
    "                    if not row or len(row) < 2:\n",
    "                        continue\n",
    "                    try:\n",
    "                        E_list.append(float(row[0]))\n",
    "                        f_list.append(float(row[1]))\n",
    "                    except Exception:\n",
    "                        continue\n",
    "            else:\n",
    "                for row in reader:\n",
    "                    try:\n",
    "                        E_list.append(float(row[ek]))\n",
    "                        f_list.append(float(row[fk]))\n",
    "                    except Exception:\n",
    "                        continue\n",
    "        return np.asarray(E_list, dtype=float), np.asarray(f_list, dtype=float)\n",
    "\n",
    "\n",
    "def compute_optical_properties(sticks_csv, prefix=\"optical\", broaden_sigma=0.1, atoms=None):\n",
    "\n",
    "    # -----------------------------------------------------\n",
    "    # Load TDDFT stick spectrum\n",
    "    # -----------------------------------------------------\n",
    "    if not os.path.isfile(sticks_csv):\n",
    "        raise FileNotFoundError(f\"Sticks CSV not found: {sticks_csv}\")\n",
    "    E_sticks, f_sticks = _read_sticks_csv(sticks_csv)\n",
    "    if E_sticks.size == 0 or f_sticks.size == 0:\n",
    "        raise ValueError(\"No data found in sticks CSV.\")\n",
    "\n",
    "    # Continuous energy grid (avoid zero exactly)\n",
    "    Emax = float(np.nanmax(E_sticks)) if np.isfinite(E_sticks).any() else 10.0\n",
    "    x = np.linspace(0.001, max(0.5, Emax) + 2.0, 1500)\n",
    "    y = np.zeros_like(x)\n",
    "\n",
    "    # Place sticks on nearest grid index for later smoothing\n",
    "    idxs = np.searchsorted(x, np.clip(E_sticks, x[0], x[-1]))\n",
    "    idxs = np.clip(idxs, 0, len(x) - 1)\n",
    "    np.add.at(y, idxs, f_sticks)\n",
    "\n",
    "    # Broadening\n",
    "    if _gaussian_filter1d is not None:\n",
    "        # approximate mapping from eV sigma to sample sigma\n",
    "        sample_sigma = max(0.5, broaden_sigma / (x[1] - x[0]))\n",
    "        y = _gaussian_filter1d(y, sample_sigma)\n",
    "    else:\n",
    "        # numpy fallback: convolve with a Gaussian kernel\n",
    "        dx = x[1] - x[0]\n",
    "        sample_sigma = max(1.0, broaden_sigma / dx)\n",
    "        half_width = int(4 * sample_sigma)\n",
    "        t = np.arange(-half_width, half_width + 1)\n",
    "        kernel = np.exp(-0.5 * (t / sample_sigma) ** 2)\n",
    "        kernel /= kernel.sum() if kernel.sum() != 0 else 1.0\n",
    "        y = np.convolve(y, kernel, mode='same')\n",
    "\n",
    "    # -----------------------------------------------------\n",
    "    # Physical constants\n",
    "    # -----------------------------------------------------\n",
    "    eV_to_J = 1.602176634e-19\n",
    "    hbar = 1.054571817e-34\n",
    "    c = 2.99792458e8\n",
    "    eps0 = 8.854187817e-12\n",
    "\n",
    "    # -----------------------------------------------------\n",
    "    # Volume normalization (m³)\n",
    "    # -----------------------------------------------------\n",
    "    if atoms is not None:\n",
    "        try:\n",
    "            volume = float(atoms.get_volume()) * (1e-10) ** 3  # Å^3 → m^3\n",
    "        except Exception:\n",
    "            volume = (10e-10) ** 3\n",
    "    else:\n",
    "        volume = (10e-10) ** 3  # ~1 nm³\n",
    "    print(f\"Using normalization volume = {volume:.3e} m³\")\n",
    "\n",
    "    # -----------------------------------------------------\n",
    "    # Dielectric function (model based on broadened oscillator strength)\n",
    "    # -----------------------------------------------------\n",
    "    eps2 = (2 * np.pi * eV_to_J * y) / (max(volume, 1e-30) * eps0)\n",
    "\n",
    "    # Kramers–Kronig for eps1\n",
    "    eps1 = np.empty_like(eps2)\n",
    "    tiny = 1e-6\n",
    "    for i, Ei in enumerate(x):\n",
    "        denom = x**2 - Ei**2\n",
    "        # Principal-value style: exclude a tiny neighborhood around the singularity\n",
    "        mask = np.abs(denom) > tiny\n",
    "        integrand = np.zeros_like(x)\n",
    "        integrand[mask] = (eps2[mask] * x[mask]) / denom[mask]\n",
    "        if _simpson is not None:\n",
    "            val = (2.0 / np.pi) * _simpson(integrand, x=x)\n",
    "        else:\n",
    "            val = (2.0 / np.pi) * np.trapz(integrand, x)\n",
    "        eps1[i] = 1.0 + val\n",
    "    # Replace any non-finite values in eps1 to prevent propagation\n",
    "    eps1 = np.nan_to_num(eps1, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "    # -----------------------------------------------------\n",
    "    # Optical quantities\n",
    "    # -----------------------------------------------------\n",
    "    # Use hypot to avoid overflow/underflow in sqrt(eps1**2 + eps2**2)\n",
    "    root = np.hypot(eps1, eps2)\n",
    "    n = np.sqrt(np.maximum(0.5 * (root + eps1), 0.0))\n",
    "    kappa = np.sqrt(np.maximum(0.5 * (root - eps1), 0.0))\n",
    "    # Absorption coefficient: α = 2 κ ω / c, with ω = E/ħ; convert m⁻1 → cm⁻1 by /100\n",
    "    alpha = (2.0 * kappa * (x * eV_to_J) / hbar) / (c * 100.0)  # cm⁻1\n",
    "    # Ensure downstream quantities are finite\n",
    "    n = np.nan_to_num(n, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    kappa = np.nan_to_num(kappa, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    alpha = np.nan_to_num(alpha, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "    # -----------------------------------------------------\n",
    "    # Save processed data\n",
    "    # -----------------------------------------------------\n",
    "    out_csv = os.path.join(DATA_DIR, f\"{prefix}_optical_properties_scaled.csv\")\n",
    "    data = np.column_stack([x, eps1, eps2, n, kappa, alpha])\n",
    "    header = \"Energy(eV),eps1,eps2,n,kappa,alpha(cm^-1)\"\n",
    "    np.savetxt(out_csv, data, delimiter=\",\", header=header, comments=\"\")\n",
    "\n",
    "    # -----------------------------------------------------\n",
    "    # Plot\n",
    "    # -----------------------------------------------------\n",
    "    mask = np.isfinite(x) & np.isfinite(alpha) & (x > 0)\n",
    "    x_valid, alpha_valid, n_valid = x[mask], alpha[mask], n[mask]\n",
    "\n",
    "    fig, ax1 = plt.subplots(figsize=(6.5, 4.3))\n",
    "    ax1.plot(x_valid, alpha_valid / 1e5, color='tab:blue', lw=1.2, label='Absorption (×1e5 cm⁻¹)')\n",
    "    ax1.set_xlabel(\"Energy (eV)\")\n",
    "    ax1.set_ylabel(\"Absorption coefficient α (×10^5 cm⁻¹)\", color='tab:blue')\n",
    "    ax1.tick_params(axis='y', labelcolor='tab:blue')\n",
    "\n",
    "    # Twin axis for refractive index\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.plot(x_valid, n_valid, color='tab:orange', lw=1.1, label='Refractive Index n(E)')\n",
    "    ax2.set_ylabel(\"Refractive Index\", color='tab:orange')\n",
    "    ax2.tick_params(axis='y', labelcolor='tab:orange')\n",
    "\n",
    "    # Top wavelength axis (inverted: longer lambda at left, shorter at right)\n",
    "    def ev_to_nm(E):\n",
    "        return np.clip(1240.0 / np.maximum(E, 1e-3), 100.0, 2000.0)\n",
    "\n",
    "    def nm_to_ev(lam):\n",
    "        return np.clip(1240.0 / np.maximum(lam, 1e-3), 0.1, 15.0)\n",
    "\n",
    "    ax3 = ax1.secondary_xaxis('top', functions=(ev_to_nm, nm_to_ev))\n",
    "    ax3.set_xlabel(\"Wavelength (nm)\", labelpad=12)\n",
    "    ax3.tick_params(axis='x', pad=10, labelsize=8, direction='out')\n",
    "\n",
    "    # Invert so that low energy ↔ long wavelength align physically\n",
    "    ax3.invert_xaxis()\n",
    "\n",
    "    def _set_wavelength_ticks_custom():\n",
    "        E_min, E_max = ax1.get_xlim()\n",
    "        wl_lo = ev_to_nm(E_max)\n",
    "        wl_hi = ev_to_nm(E_min)\n",
    "        lo, hi = (min(wl_lo, wl_hi), max(wl_lo, wl_hi))\n",
    "        if not np.isfinite(lo) or not np.isfinite(hi) or hi - lo < 1e-6:\n",
    "            ax3.xaxis.set_major_locator(mticker.FixedLocator([]))\n",
    "            return\n",
    "        candidates = np.array([150, 200, 250, 300, 350, 400, 450, 500, 650])\n",
    "        ticks = candidates[(candidates >= lo) & (candidates <= hi)]\n",
    "        ax3.xaxis.set_major_locator(mticker.FixedLocator(ticks))\n",
    "        ax3.xaxis.set_major_formatter(mticker.StrMethodFormatter('{x:.0f}'))\n",
    "        ax3.get_xaxis().get_offset_text().set_visible(False)\n",
    "\n",
    "    def _on_xlim_change(_ax):\n",
    "        _set_wavelength_ticks_custom()\n",
    "\n",
    "    ax1.callbacks.connect('xlim_changed', _on_xlim_change)\n",
    "    _set_wavelength_ticks_custom()\n",
    "\n",
    "    # Highlight and annotate UV transition\n",
    "    if x_valid.size:\n",
    "        yref = max(alpha_valid / 1e5) if np.size(alpha_valid) else 1.0\n",
    "        ax1.axvspan(7.5, 9.0, color='gray', alpha=0.15, label=\"UV absorption region\")\n",
    "        ax1.annotate(\n",
    "            \"Main transition\\n8.192 eV (151 nm): UV absorp. region\",\n",
    "            xy=(8.5, yref * 0.8),\n",
    "            xytext=(6.0, yref * 0.9),\n",
    "            arrowprops=dict(arrowstyle=\"->\", color='black', lw=0.8),\n",
    "            fontsize=9,\n",
    "        )\n",
    "\n",
    "    # Inset (low-energy tail) if inset_axes is available\n",
    "    if _inset_axes is not None and x_valid.size:\n",
    "        ax_inset = _inset_axes(ax1, width=\"40%\", height=\"35%\", loc='lower right')\n",
    "        ax_inset.plot(x_valid, alpha_valid / 1e5, color='tab:blue', lw=1)\n",
    "        ax_inset.set_xlim(2, 4)\n",
    "        mask24 = (x_valid > 2) & (x_valid < 4)\n",
    "        if np.any(mask24):\n",
    "            ax_inset.set_ylim(0, float(np.max(alpha_valid[mask24] / 1e5)) * 1.2)\n",
    "        ax_inset.set_title(\"Low-Energy Tail\", fontsize=8)\n",
    "        ax_inset.tick_params(axis='both', labelsize=7)\n",
    "\n",
    "    fig.suptitle(f\"{prefix} Optical Properties (Energy–Wavelength)\", fontsize=11)\n",
    "\n",
    "    # -----------------------------------------------------\n",
    "    # suppress warnings\n",
    "    # -----------------------------------------------------\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\", UserWarning)\n",
    "        plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "\n",
    "    try:\n",
    "        OUT_DIR\n",
    "    except NameError:\n",
    "        _project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "        OUT_DIR = os.path.join(_project_root, \"spectra-results\")\n",
    "        os.makedirs(OUT_DIR, exist_ok=True)\n",
    "    out_fig = os.path.join(OUT_DIR, f\"{prefix}_optical.png\")\n",
    "    plt.savefig(out_fig, dpi=500, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    return out_csv, out_fig\n",
    "\n",
    "optical_files = compute_optical_properties(os.path.join(DATA_DIR, \"caf2_cluster_sticks.csv\"), prefix=\"CaF₂ Cluster\")"
   ],
   "id": "afdb7d4d39de649a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- Load the data ---\n",
    "df = pd.read_csv(os.path.join(DATA_DIR, \"caf2_cluster_sticks.csv\"))\n",
    "colE = [c for c in df.columns if \"Energy\" in c][0]\n",
    "colF = [c for c in df.columns if \"Osc\" in c or \"f\" in c][0]\n",
    "\n",
    "E = df[colE].astype(float).to_numpy()\n",
    "F = df[colF].astype(float).to_numpy()\n",
    "\n",
    "# Normalize intensity\n",
    "intensity = F / np.max(F)\n",
    "\n",
    "# --- Find strongest transition ---\n",
    "idx_max = np.argmax(F)\n",
    "E_max = E[idx_max]\n",
    "F_max = F[idx_max]\n",
    "λ_max = 1240.0 / np.maximum(E_max, 1e-9)\n",
    "\n",
    "print(f\"[Peak] Strongest transition: {E_max:.3f} eV  |  {λ_max:.1f} nm  |  f = {F_max:.3f}\")\n",
    "\n",
    "# --- Define EM bands ---\n",
    "E_min, E_max_plot = 0.5, 10.0\n",
    "IR_lo, IR_hi = 0.5, 1.65\n",
    "VIS_lo, VIS_hi = 1.65, 3.10\n",
    "UV_lo, UV_hi = 3.10, 10.0\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 3), dpi=200)\n",
    "ax.hlines(1, E_min, E_max_plot, linewidth=4, alpha=0.3)\n",
    "\n",
    "def add_band(x0, x1, label, color, alpha=0.15):\n",
    "    ax.fill_between([x0, x1], [0.8, 0.8], [1.2, 1.2], alpha=alpha, step=\"mid\", color=color)\n",
    "    ax.text((x0 + x1)/2, 1.27, label, ha='center', va='bottom', fontsize=11)\n",
    "\n",
    "add_band(IR_lo, IR_hi,  \"Infrared (IR)\", \"steelblue\")\n",
    "add_band(VIS_lo, VIS_hi, \"Visible\", \"#8B4513\")\n",
    "add_band(UV_lo,  UV_hi,  \"Ultraviolet (UV)\", \"darkgreen\")\n",
    "\n",
    "# --- Plot intensity curve ---\n",
    "scaled_y = 0.4 * intensity + 0.85\n",
    "ax.plot(E, scaled_y, color='tab:blue', lw=1.5)\n",
    "ax.fill_between(E, 0.85, scaled_y, color='tab:blue', alpha=0.25)\n",
    "\n",
    "# --- Highlight the real strongest transition ---\n",
    "ax.axvline(E[idx_max], color='red', lw=1, ls='--', alpha=0.8)\n",
    "ax.text(E[idx_max] + 0.1, 1.26,\n",
    "        f\"{E[idx_max]:.2f} eV\\n({λ_max:.0f} nm)\",\n",
    "        color='red', fontsize=9, va='bottom')\n",
    "\n",
    "# --- Axis setup ---\n",
    "ax.set_xlim(E_min, E_max_plot)\n",
    "ax.set_ylim(0.7, 1.45)\n",
    "ax.set_xlabel(\"Photon Energy (eV)\", fontsize=10)\n",
    "ax.set_yticks([])\n",
    "ax.tick_params(axis='x', labelsize=9)\n",
    "\n",
    "# --- Top wavelength axis ---\n",
    "def E_to_lambda(E): return 1240 / np.maximum(E, 1e-3)\n",
    "def lambda_to_E(lam): return 1240 / np.maximum(lam, 1e-3)\n",
    "\n",
    "secax = ax.secondary_xaxis('top', functions=(E_to_lambda, lambda_to_E))\n",
    "secax.set_xlabel(\"Wavelength (nm)\", fontsize=10)\n",
    "secax.set_xticks([2000, 1000, 750, 650, 500, 400, 300, 200, 150, 124])\n",
    "secax.set_xticklabels([str(int(t)) for t in [2000, 1000, 750, 650, 500, 400, 300, 200, 150, 124]])\n",
    "secax.invert_xaxis()\n",
    "\n",
    "fig.suptitle(\"CaF₂ Cluster — Optical Intensity with Strongest Transition\", fontsize=12, y=0.98)\n",
    "plt.tight_layout()\n",
    "try:\n",
    "    OUT_DIR\n",
    "except NameError:\n",
    "    _project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "    OUT_DIR = os.path.join(_project_root, \"Q-UCSpec/spectra-results\")\n",
    "    os.makedirs(OUT_DIR, exist_ok=True)\n",
    "plt.savefig(os.path.join(OUT_DIR, \"caf2_cluster_peak.png\"), dpi=500, bbox_inches='tight')\n",
    "plt.show()"
   ],
   "id": "4a939121331a0af6",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPAW TDDFT (legacy)",
   "language": "python",
   "name": "gpaw-tddft-legacy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
